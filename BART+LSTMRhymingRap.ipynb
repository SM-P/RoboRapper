{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BART+XLNetRhymingRap.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d91edb4d9a34428dab830f29e4d1161b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_05261e5265c045909553e653f6a5cd1d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26cb3bcaadb3405a83b123dcab3aa15d",
              "IPY_MODEL_2e7d5cfd2f8f4624bcbf7afe76ec9012"
            ]
          }
        },
        "05261e5265c045909553e653f6a5cd1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "26cb3bcaadb3405a83b123dcab3aa15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21c3224afcf3441d9efce5ab6dafc115",
            "_dom_classes": [],
            "description": "Validation sanity check:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8127b19248514aaf971743d0c7b11934"
          }
        },
        "2e7d5cfd2f8f4624bcbf7afe76ec9012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca135c6fe29c47188b8a0dce3d35e339",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [15:21&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e03595d0dd04ad59e3d9902d65c676a"
          }
        },
        "21c3224afcf3441d9efce5ab6dafc115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8127b19248514aaf971743d0c7b11934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca135c6fe29c47188b8a0dce3d35e339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e03595d0dd04ad59e3d9902d65c676a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea6731a886e94debbfef3123ee2507fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_83ec948e2dfb470b91ad36703f4052eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_09c39593b55f4405b13b16f3958ffb9e",
              "IPY_MODEL_15e1db8c42e442dc8944de44611e0ceb"
            ]
          }
        },
        "83ec948e2dfb470b91ad36703f4052eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "09c39593b55f4405b13b16f3958ffb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d4e9606f23824c96ae7f72a8b42dcac2",
            "_dom_classes": [],
            "description": "Epoch 1: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8da2f8cc44fb4f7891baceba008fd58a"
          }
        },
        "15e1db8c42e442dc8944de44611e0ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_52964696192a41149c9448dfd9fac197",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7000/7000 [07:38&lt;00:00, 15.27it/s, loss=3.97, v_num=1]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3d8e028479948758951506f41159e8d"
          }
        },
        "d4e9606f23824c96ae7f72a8b42dcac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8da2f8cc44fb4f7891baceba008fd58a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52964696192a41149c9448dfd9fac197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3d8e028479948758951506f41159e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f002d6d49034c2591d0bc4eda3e94f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e2c9b41b26cd4893b640023f60802308",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d129b3ad5a5e48849657d0d6d2a3fd45",
              "IPY_MODEL_663f7c48423e4b9196a700463b07c049"
            ]
          }
        },
        "e2c9b41b26cd4893b640023f60802308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "d129b3ad5a5e48849657d0d6d2a3fd45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e4acd71068294c4f81f051caab7c3dd7",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1750,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1750,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a671e0339d8d4b3b8d48945eb07aaeb7"
          }
        },
        "663f7c48423e4b9196a700463b07c049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_679fdcf41dae495b90fab50d86b1f2be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1750/1750 [00:33&lt;00:00, 52.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_494eec0424964f428785667b169224fe"
          }
        },
        "e4acd71068294c4f81f051caab7c3dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a671e0339d8d4b3b8d48945eb07aaeb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "679fdcf41dae495b90fab50d86b1f2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "494eec0424964f428785667b169224fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cc3239d433c4e039e7f50d024f8d982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d93eafc890c4e148933bf6caa8115c7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b46941c40cb149fbae0bb7a5654f885b",
              "IPY_MODEL_685908bc1fcf4617a1723c5dceea3ebb"
            ]
          }
        },
        "0d93eafc890c4e148933bf6caa8115c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "b46941c40cb149fbae0bb7a5654f885b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d8cbed43d49d4f17add99c9433b91d92",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1750,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1750,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33b71bdd570740588b1a9f02b4593faa"
          }
        },
        "685908bc1fcf4617a1723c5dceea3ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_92a154a458d1445fb01a70f72a8071d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1750/1750 [00:33&lt;00:00, 52.31it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12f9a69ebabe491fb683181fb86026eb"
          }
        },
        "d8cbed43d49d4f17add99c9433b91d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33b71bdd570740588b1a9f02b4593faa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92a154a458d1445fb01a70f72a8071d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12f9a69ebabe491fb683181fb86026eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHAjt_gmPE-1"
      },
      "source": [
        "##Setup\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7EVTfMVdv4Z"
      },
      "source": [
        "!pip install -q pytorch-lightning\n",
        "!pip install -q transformers"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fDnjiDoeZbK"
      },
      "source": [
        "import transformers\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import math\n",
        "import random\n",
        "import re\n",
        "import argparse\n",
        "import ast\n",
        "import io\n",
        "from tqdm import tqdm, trange"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "O48p2-T9J7lb",
        "outputId": "f259a8a1-616b-426d-e62e-89300f667341"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()\r\n",
        "uploaded1 = files.upload()\r\n",
        "uploaded2 = files.upload()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-799d6f60-1abf-4665-87e4-6911dcd00c29\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-799d6f60-1abf-4665-87e4-6911dcd00c29\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9e35c0be-88fd-4cbb-82a9-465073bd0f9c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9e35c0be-88fd-4cbb-82a9-465073bd0f9c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1ef33fee-fa63-4baf-8a55-ed3974dc6bea\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1ef33fee-fa63-4baf-8a55-ed3974dc6bea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbo4w7eMkiRv"
      },
      "source": [
        "##BART Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Goj88fbbQ3Wo",
        "outputId": "75a1bef7-7f70-4fe3-ce50-bea8250baf1b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'BART/'"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPxWynRmeGlL"
      },
      "source": [
        "class LitModel(pl.LightningModule):\n",
        "  # Instantiate the model\n",
        "  def __init__(self, learning_rate, tokenizer, model, hparams):\n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.model = model\n",
        "    self.learning_rate = learning_rate\n",
        "    self.hparams = hparams\n",
        "\n",
        "    if self.hparams.freeze_encoder:\n",
        "      freeze_params(self.model.get_encoder())\n",
        "\n",
        "    if self.hparams.freeze_embeds:\n",
        "      self.freeze_embeds()\n",
        "  \n",
        "  def freeze_embeds(self):\n",
        "    ''' freeze the positional embedding parameters of the model; adapted from finetune.py '''\n",
        "    freeze_params(self.model.model.shared)\n",
        "    for d in [self.model.model.encoder, self.model.model.decoder]:\n",
        "      freeze_params(d.embed_positions)\n",
        "      freeze_params(d.embed_tokens)\n",
        "\n",
        "  # Do a forward pass through the model\n",
        "  def forward(self, input_ids, **kwargs):\n",
        "    return self.model(input_ids, **kwargs)\n",
        "  \n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr = self.learning_rate)\n",
        "    return optimizer\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    # Load the data into variables\n",
        "    src_ids, src_mask = batch[0], batch[1]\n",
        "    tgt_ids = batch[2]\n",
        "    # Shift the decoder tokens right (but NOT the tgt_ids)\n",
        "    decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
        "\n",
        "    # Run the model and get the logits\n",
        "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
        "    lm_logits = outputs[0]\n",
        "    # Create the loss function\n",
        "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
        "    # Calculate the loss on the un-shifted tokens\n",
        "    loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
        "    return {'loss':loss}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "\n",
        "    src_ids, src_mask = batch[0], batch[1]\n",
        "    tgt_ids = batch[2]\n",
        "\n",
        "    decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
        "    \n",
        "    # Run the model and get the logits\n",
        "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
        "    lm_logits = outputs[0]\n",
        "\n",
        "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
        "    val_loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
        "\n",
        "    return {'loss': val_loss}\n",
        "  \n",
        "  # Method that generates text using the BartForConditionalGeneration's generate() method\n",
        "  def generate_text(self, text, eval_beams, early_stopping = True, max_len = 40, startT = None):\n",
        "    ''' Function to generate text '''\n",
        "    if startT == None:\n",
        "      dstartT = self.tokenizer.pad_token_id\n",
        "    else:\n",
        "      dstartT = tokenizer.convert_tokens_to_ids(startT)\n",
        "    generated_ids = self.model.generate(\n",
        "        text[\"input_ids\"],\n",
        "        attention_mask=text[\"attention_mask\"],\n",
        "        use_cache=True,\n",
        "        decoder_start_token_id = dstartT,\n",
        "        num_beams= eval_beams,\n",
        "        max_length = max_len,\n",
        "        early_stopping = early_stopping\n",
        "    )\n",
        "    return [self.tokenizer.decode(w, skip_special_tokens=True, clean_up_tokenization_spaces=True) for w in generated_ids]\n",
        "\n",
        "def freeze_params(model):\n",
        "  ''' Function that takes a model as input (or part of a model) and freezes the layers for faster training\n",
        "      adapted from finetune.py '''\n",
        "  for layer in model.parameters():\n",
        "    layer.requires_grade = False\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cUIEJBIjjNJ"
      },
      "source": [
        "# Create a dataloading module as per the PyTorch Lightning Docs\n",
        "class SummaryDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, tokenizer, data_file, batch_size, num_examples = 20000):\n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data_file = data_file\n",
        "    self.batch_size = batch_size\n",
        "    self.num_examples = num_examples\n",
        "  \n",
        "  # Loads and splits the data into training, validation and test sets with a 60/20/20 split\n",
        "  def prepare_data(self):\n",
        "    self.data = pd.read_csv(self.data_file)[:self.num_examples]\n",
        "    self.train, self.validate, self.test = np.split(self.data.sample(frac=1), [int(.6*len(self.data)), int(.8*len(self.data))])\n",
        "\n",
        "  # encode the sentences using the tokenizer  \n",
        "  def setup(self, stage):\n",
        "    self.train = encode_sentences(self.tokenizer, self.train['source'], self.train['target'])\n",
        "    self.validate = encode_sentences(self.tokenizer, self.validate['source'], self.validate['target'])\n",
        "    self.test = encode_sentences(self.tokenizer, self.test['source'], self.test['target'])\n",
        "\n",
        "  # Load the training, validation and test sets in Pytorch Dataset objects\n",
        "  def train_dataloader(self):\n",
        "    dataset = TensorDataset(self.train['input_ids'], self.train['attention_mask'], self.train['labels'])                          \n",
        "    train_data = DataLoader(dataset, sampler = RandomSampler(dataset), batch_size = self.batch_size)\n",
        "    return train_data\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    dataset = TensorDataset(self.validate['input_ids'], self.validate['attention_mask'], self.validate['labels']) \n",
        "    val_data = DataLoader(dataset, batch_size = self.batch_size)                       \n",
        "    return val_data\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    dataset = TensorDataset(self.test['input_ids'], self.test['attention_mask'], self.test['labels']) \n",
        "    test_data = DataLoader(dataset, batch_size = self.batch_size)                   \n",
        "    return test_data\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibsTjaBjZ-OE"
      },
      "source": [
        "hparams = argparse.Namespace()\n",
        "\n",
        "hparams.freeze_encoder = True\n",
        "hparams.freeze_embeds = True\n",
        "hparams.eval_beams = 4"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no6DwOqaE9Jw"
      },
      "source": [
        "def shift_tokens_right(input_ids, pad_token_id):\n",
        "  \"\"\" Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\n",
        "      This is taken directly from modeling_bart.py\n",
        "  \"\"\"\n",
        "  prev_output_tokens = input_ids.clone()\n",
        "  index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n",
        "  prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n",
        "  prev_output_tokens[:, 1:] = input_ids[:, :-1]\n",
        "  return prev_output_tokens\n",
        "\n",
        "def encode_sentences(tokenizer, source_sentences, target_sentences, max_length=32, pad_to_max_length=True, return_tensors=\"pt\"):\n",
        "  ''' Function that tokenizes a sentence \n",
        "      Args: tokenizer - the BART tokenizer; source and target sentences are the source and target sentences\n",
        "      Returns: Dictionary with keys: input_ids, attention_mask, target_ids\n",
        "  '''\n",
        "\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  target_ids = []\n",
        "  tokenized_sentences = {}\n",
        "\n",
        "  for sentence in source_sentences:\n",
        "    encoded_dict = tokenizer(\n",
        "          sentence,\n",
        "          max_length=max_length,\n",
        "          padding=\"max_length\" if pad_to_max_length else None,\n",
        "          truncation=True,\n",
        "          return_tensors=return_tensors,\n",
        "          add_prefix_space = True\n",
        "      )\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim = 0)\n",
        "  attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "\n",
        "  for sentence in target_sentences:\n",
        "    encoded_dict = tokenizer(\n",
        "          sentence,\n",
        "          max_length=max_length,\n",
        "          padding=\"max_length\" if pad_to_max_length else None,\n",
        "          truncation=True,\n",
        "          return_tensors=return_tensors,\n",
        "          add_prefix_space = True\n",
        "      )\n",
        "    # Shift the target ids to the right\n",
        "    # shifted_target_ids = shift_tokens_right(encoded_dict['input_ids'], tokenizer.pad_token_id)\n",
        "    target_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "  target_ids = torch.cat(target_ids, dim = 0)\n",
        "  \n",
        "\n",
        "  batch = {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"attention_mask\": attention_masks,\n",
        "      \"labels\": target_ids,\n",
        "  }\n",
        "\n",
        "  return batch\n",
        "\n",
        "\n",
        "def noise_sentence(sentence_, percent_words, replacement_token = \"<mask>\"):\n",
        "  '''\n",
        "  Function that noises a sentence by adding <mask> tokens\n",
        "  Args: sentence - the sentence to noise\n",
        "        percent_words - the percent of words to replace with <mask> tokens; the number is rounded up using math.ceil\n",
        "  Returns a noised sentence\n",
        "  '''\n",
        "  # Create a list item and copy\n",
        "  sentence_ = sentence_.split(' ')\n",
        "  sentence = sentence_.copy()\n",
        "  \n",
        "  num_words = math.ceil(len(sentence) * percent_words)\n",
        "  \n",
        "  # Create an array of tokens to sample from; don't include the last word as an option because in the case of lyrics\n",
        "  # that word is often a rhyming word and plays an important role in song construction\n",
        "  sample_tokens = set(np.arange(0, np.maximum(1, len(sentence))))\n",
        "  \n",
        "  words_to_noise = random.sample(sample_tokens, num_words)\n",
        "  \n",
        "  # Swap out words, but not full stops\n",
        "  for pos in words_to_noise:\n",
        "      if sentence[pos] != '.':\n",
        "          sentence[pos] = replacement_token\n",
        "  \n",
        "  # Remove redundant spaces\n",
        "  sentence = re.sub(r' {2,5}', ' ', ' '.join(sentence))\n",
        "  \n",
        "  # Combine concurrent <mask> tokens into a single token; this just does two rounds of this; more could be done\n",
        "  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n",
        "  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n",
        "  return sentence\n",
        "  "
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAKO4lHfiJMP"
      },
      "source": [
        "# Load the model\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, BartConfig, BartModel\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base', add_prefix_space=True)\n",
        "\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(\n",
        "    \"facebook/bart-base\")\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h8QhLcyh9RJ"
      },
      "source": [
        "# Load the data into the model for training\n",
        "summary_data = SummaryDataModule(tokenizer, '/content/gdrive/My Drive/BART learns to rap/lyrics_simple_noised.csv',\n",
        "                                 batch_size = 16, num_examples = 140000)\n",
        "\n",
        "# Load the model from a pre-saved checkpoint; alternatively use the code below to start training from scratch\n",
        "# model = LitModel.load_from_checkpoint(base_dir + \"checkpoint_files_2/8_ep_140k_simple_0210.ckpt\",\n",
        "#                                       learning_rate = 2e-5, tokenizer = tokenizer, model = bart_model, hparams = hparams)\n",
        "\n",
        "model = LitModel(learning_rate = 2e-5, tokenizer = tokenizer, model = bart_model, hparams = hparams)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAj9wgyRXbRG",
        "outputId": "f5fd053b-dc04-4789-9b72-f8871d347709"
      },
      "source": [
        "#checkpoint = ModelCheckpoint(filepath=base_dir + 'checkpoint_files_2/')\n",
        "trainer = pl.Trainer(gpus = 1,\n",
        "                     max_epochs = 2,\n",
        "                     min_epochs = 2,\n",
        "                     auto_lr_find = False,\n",
        "                     \n",
        "                     progress_bar_refresh_rate = 500)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWccEjPWwhHW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "d91edb4d9a34428dab830f29e4d1161b",
            "05261e5265c045909553e653f6a5cd1d",
            "26cb3bcaadb3405a83b123dcab3aa15d",
            "2e7d5cfd2f8f4624bcbf7afe76ec9012",
            "21c3224afcf3441d9efce5ab6dafc115",
            "8127b19248514aaf971743d0c7b11934",
            "ca135c6fe29c47188b8a0dce3d35e339",
            "8e03595d0dd04ad59e3d9902d65c676a",
            "ea6731a886e94debbfef3123ee2507fc",
            "83ec948e2dfb470b91ad36703f4052eb",
            "09c39593b55f4405b13b16f3958ffb9e",
            "15e1db8c42e442dc8944de44611e0ceb",
            "d4e9606f23824c96ae7f72a8b42dcac2",
            "8da2f8cc44fb4f7891baceba008fd58a",
            "52964696192a41149c9448dfd9fac197",
            "f3d8e028479948758951506f41159e8d",
            "2f002d6d49034c2591d0bc4eda3e94f7",
            "e2c9b41b26cd4893b640023f60802308",
            "d129b3ad5a5e48849657d0d6d2a3fd45",
            "663f7c48423e4b9196a700463b07c049",
            "e4acd71068294c4f81f051caab7c3dd7",
            "a671e0339d8d4b3b8d48945eb07aaeb7",
            "679fdcf41dae495b90fab50d86b1f2be",
            "494eec0424964f428785667b169224fe",
            "8cc3239d433c4e039e7f50d024f8d982",
            "0d93eafc890c4e148933bf6caa8115c7",
            "b46941c40cb149fbae0bb7a5654f885b",
            "685908bc1fcf4617a1723c5dceea3ebb",
            "d8cbed43d49d4f17add99c9433b91d92",
            "33b71bdd570740588b1a9f02b4593faa",
            "92a154a458d1445fb01a70f72a8071d4",
            "12f9a69ebabe491fb683181fb86026eb"
          ]
        },
        "outputId": "6e35be38-3661-4f5e-cee8-6a9dfa4fc923"
      },
      "source": [
        "# Fit the instantiated model to the data\n",
        "trainer.fit(model, summary_data)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name  | Type                         | Params\n",
            "-------------------------------------------------------\n",
            "0 | model | BartForConditionalGeneration | 139 M \n",
            "-------------------------------------------------------\n",
            "139 M     Trainable params\n",
            "0         Non-trainable params\n",
            "139 M     Total params\n",
            "557.682   Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d91edb4d9a34428dab830f29e4d1161b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea6731a886e94debbfef3123ee2507fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f002d6d49034c2591d0bc4eda3e94f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cc3239d433c4e039e7f50d024f8d982",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj6WYHbFO_9V"
      },
      "source": [
        "\n",
        "\n",
        "def generate_lyrics(seed_line, num_lines, model_, startW, noise_percent = 0.25, multiple_lines = False, max_line_history = 3):\n",
        "  ''' Function that generates lyrics based on previously generated lyrics \n",
        "      Args: seed_line - a line to start off the machine\n",
        "            num_lines - the number of lines to generate\n",
        "            model_ - the model used to generate the text\n",
        "            multiple_lines - whether the model generates based on multiple previous lines or just the past line\n",
        "            max_line_history - the maximum number of previous lines used in the current input\n",
        "      Returns a list with num_lines of rap lines\n",
        "  '''\n",
        "  # Put the model on eval mode\n",
        "  model_.to(torch.device('cpu'))\n",
        "  model_.eval()\n",
        "  lyrics = []\n",
        "  lyrics.append(seed_line)\n",
        "  prompt_line_tokens = tokenizer(noise_sentence(seed_line, 0.2), max_length = 32, return_tensors = \"pt\", truncation = True)\n",
        "  # Loop through the number of lines generating a new line based on the old\n",
        "\n",
        "  line = [seed_line]\n",
        "  for i in range(num_lines):\n",
        "    # Print out the new line\n",
        "    print(line[0].strip())\n",
        "    lyrics.append(line[0])\n",
        "    line = model.generate_text(prompt_line_tokens, eval_beams = 4, startT = startW)\n",
        "    # This deals with an artefact in the training data that I had an issue cleaning\n",
        "    if line[0].find(\":\") != -1:\n",
        "      line[0] = re.sub(r'[A-Z]+: ', '', line[0])\n",
        "    # This allows the model to generate a new line conditioned on more than one line\n",
        "    if multiple_lines:\n",
        "      start_line = np.maximum(0, i - max_line_history)\n",
        "      end_line = i\n",
        "      prompt_line = ' '.join(lyrics[start_line:end_line]) # Going to end_line is fine because it is non-inclusive\n",
        "    else:\n",
        "      prompt_line = lyrics[i]\n",
        "    prompt_line_tokens = tokenizer(noise_sentence(prompt_line, noise_percent), max_length = 32, return_tensors = \"pt\", truncation = True)\n",
        "\n",
        "  return lyrics"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooqo4fVQ2zWV"
      },
      "source": [
        "# LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcvLaLwLgYpg"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "MIN_WORD_FREQUENCY = 10\n",
        "SEQUENCE_LEN = 5\n",
        "EPOCH = 6"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkEfEIikB2TI"
      },
      "source": [
        "#open file and save it in to list \n",
        "with open('outRlyrics.txt', 'r') as content_file:\n",
        "    content = content_file.read()\n",
        "songlyrics = content.split(\"\\\"\")\n",
        "\n",
        "#cleaning - removing empty elements from the list\n",
        "clean_songlyrics = []\n",
        "for item in songlyrics:\n",
        "  if len(item)>1:\n",
        "    clean_songlyrics.append(item)\n",
        "\n",
        "#make a list(lyrics) of list(sentences)\n",
        "Llyrics = []\n",
        "for l in clean_songlyrics:\n",
        "  sentences = l.split(\"\\n\")\n",
        "  Llyrics.append(sentences)\n",
        "\n",
        "#cleaning - removing empty elements from sentences of each lyric\n",
        "Llyrics = [[s for s in l if len(s)>1] for l in Llyrics ]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAzr5CCJCAus"
      },
      "source": [
        "#cleaning - removing brackets from the main list (Llyrics)\n",
        "import re\n",
        "regex = re.compile(\".*?\\[(.*?)\\]\")\n",
        "\n",
        "bracket = []\n",
        "for i in range(len(Llyrics)):\n",
        "  for j in range(len(Llyrics[i])):\n",
        "    result = re.findall(regex, Llyrics[i][j])\n",
        "    for item in result:\n",
        "      #keep them in the bracket list\n",
        "      if item not in bracket:\n",
        "        bracket.append(item)\n",
        "      #remove the brackets from the sentences\n",
        "      Llyrics[i][j] = Llyrics[i][j].replace(\"[\"+item+\"]\", \"\")\n",
        "    \n",
        "#cleaning- remove empty elements (sentences) appeared on each lyric\n",
        "Llyrics[i] = [s for s in Llyrics[i] if len(s)>1]\n",
        "\n",
        "for i in range(len(Llyrics)):\n",
        "  for j in range(len(Llyrics[i])):\n",
        "    Llyrics[i][j] += \"\\n\""
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhpCi-BACHZW"
      },
      "source": [
        "text_in_words = [w.lower()   for l in Llyrics for s in l for w in s.split(' ') if len(w)>0]\n",
        "\n",
        "word_freq = {}\n",
        "for word in text_in_words:\n",
        "    word_freq[word] = word_freq.get(word, 0) + 1\n",
        "    \n",
        "ignored_words = set()\n",
        "for k, v in word_freq.items():\n",
        "    if word_freq[k] < MIN_WORD_FREQUENCY:\n",
        "        ignored_words.add(k)\n",
        "        \n",
        "words = set(text_in_words)\n",
        "words = sorted(set(words) - ignored_words)\n",
        "\n",
        "word_indices = dict((c, i) for i, c in enumerate(words))\n",
        "indices_word = dict((i, c) for i, c in enumerate(words))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcoP3MZfCMGd"
      },
      "source": [
        "STEP = 1\n",
        "\n",
        "sentences = []\n",
        "next_words = []\n",
        "ignored = 0\n",
        "for i in range(0, len(text_in_words) - SEQUENCE_LEN, STEP):\n",
        "    # Only add sequences where no word is in ignored_words\n",
        "    if len(set(text_in_words[i: i+SEQUENCE_LEN+1]).intersection(ignored_words)) == 0:\n",
        "        sentences.append(text_in_words[i: i + SEQUENCE_LEN])\n",
        "        next_words.append(text_in_words[i + SEQUENCE_LEN])\n",
        "    else:\n",
        "        ignored = ignored+1"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7c0ThRvCPf_",
        "outputId": "07d2e094-643f-493e-df0e-88e48a329311",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def shuffle_and_split_training_set(sentences_original, next_original, percentage_test=2):\n",
        "    tmp_sentences = []\n",
        "    tmp_next_word = []\n",
        "    for i in np.random.permutation(len(sentences_original)):\n",
        "        tmp_sentences.append(sentences_original[i])\n",
        "        tmp_next_word.append(next_original[i])\n",
        "\n",
        "    cut_index = int(len(sentences_original) * (1.-(percentage_test/100.)))\n",
        "    x_train, x_test = tmp_sentences[:cut_index], tmp_sentences[cut_index:]\n",
        "    y_train, y_test = tmp_next_word[:cut_index], tmp_next_word[cut_index:]\n",
        "\n",
        "    print(\"Size of training set = %d\" % len(x_train))\n",
        "    print(\"Size of test set = %d\" % len(y_test))\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "sentences, next_words, sentences_test, next_words_test = shuffle_and_split_training_set(sentences, next_words)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training set = 792868\n",
            "Size of test set = 16181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd9Ger5eCS7L"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Embedding, InputLayer\n",
        "\n",
        "Lmodel = Sequential()\n",
        "Lmodel.add(Embedding(input_dim=len(words), output_dim=1024))\n",
        "Lmodel.add(Bidirectional(LSTM(128)))\n",
        "Lmodel.add(Dropout(0.2))\n",
        "Lmodel.add(Dense(len(words)))\n",
        "Lmodel.add(Activation('softmax'))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohHaRs1mCXWP"
      },
      "source": [
        "def generator(sentence_list, next_word_list, batch_size):\n",
        "    index = 0\n",
        "    while True:\n",
        "        x = np.zeros((batch_size, SEQUENCE_LEN), dtype=np.int32)\n",
        "        y = np.zeros((batch_size), dtype=np.int32)\n",
        "        for i in range(batch_size):\n",
        "            for t, w in enumerate(sentence_list[index % len(sentence_list)]):\n",
        "                x[i, t] = word_indices[w]\n",
        "            y[i] = word_indices[next_word_list[index % len(sentence_list)]]\n",
        "            index = index + 1\n",
        "        yield x, y"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFgyP7DuTlaa"
      },
      "source": [
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    examples_file.write('\\n----- Generating text after Epoch: %d\\n' % epoch)\n",
        "    # Randomly pick a seed sequence\n",
        "    seed_index = np.random.randint(len(sentences+sentences_test))\n",
        "    seed = (sentences+sentences_test)[seed_index]\n",
        "    \n",
        "    for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "        sentence = seed\n",
        "        examples_file.write('----- Diversity:' + str(diversity) + '\\n')\n",
        "        examples_file.write('----- Generating with seed:\\n\"' + ' '.join(sentence) + '\"\\n')\n",
        "        examples_file.write(' '.join(sentence))\n",
        "\n",
        "        for i in range(50):\n",
        "            x_pred = np.zeros((1, SEQUENCE_LEN, len(words)))\n",
        "            for t, word in enumerate(sentence):\n",
        "                x_pred[0, t, word_indices[word]] = 1.\n",
        "\n",
        "            preds = Lmodel.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_word = indices_word[next_index]\n",
        "\n",
        "            sentence = sentence[1:]\n",
        "            sentence.append(next_word)\n",
        "\n",
        "            examples_file.write(\" \"+next_word)\n",
        "        examples_file.write('\\n')\n",
        "    examples_file.write('='*80 + '\\n')\n",
        "    examples_file.flush()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8ZMiGXECaBC",
        "outputId": "a24c275c-fc33-4fc6-87fc-f07ac72d2362",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#training model\n",
        "\n",
        "Lmodel.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping\n",
        "file_path = \"./checkpoints/LSTM_LYRICS-epoch{epoch:03d}-words%d-sequence%d-minfreq%d-\" \\\n",
        "                \"loss{loss:.4f}-acc{acc:.4f}-val_loss{val_loss:.4f}-val_acc{val_acc:.4f}\" % \\\n",
        "                (len(words), SEQUENCE_LEN, MIN_WORD_FREQUENCY)\n",
        "\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', save_best_only=True)\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', patience=5)\n",
        "callbacks_list = [checkpoint, print_callback, early_stopping]\n",
        "\n",
        "examples_file = open(\"examples.txt\", \"w\")\n",
        "\n",
        "Lmodel.fit_generator(generator(sentences, next_words, BATCH_SIZE),\n",
        "                        steps_per_epoch=int(len(sentences)/BATCH_SIZE) + 1,\n",
        "                        epochs=EPOCH, #100\n",
        "                        validation_data=generator(sentences_test, next_words_test, BATCH_SIZE),\n",
        "                        validation_steps=int(len(sentences_test)/BATCH_SIZE) + 1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "24778/24778 [==============================] - 2010s 81ms/step - loss: 6.1611 - accuracy: 0.0930 - val_loss: 5.4885 - val_accuracy: 0.1402\n",
            "Epoch 2/6\n",
            "24778/24778 [==============================] - 2379s 96ms/step - loss: 5.4676 - accuracy: 0.1415 - val_loss: 5.3693 - val_accuracy: 0.1496\n",
            "Epoch 3/6\n",
            "24778/24778 [==============================] - 2419s 98ms/step - loss: 5.2454 - accuracy: 0.1584 - val_loss: 5.3301 - val_accuracy: 0.1537\n",
            "Epoch 4/6\n",
            "24778/24778 [==============================] - 2405s 97ms/step - loss: 5.0887 - accuracy: 0.1704 - val_loss: 5.3068 - val_accuracy: 0.1585\n",
            "Epoch 5/6\n",
            "24778/24778 [==============================] - 2405s 97ms/step - loss: 4.9709 - accuracy: 0.1817 - val_loss: 5.2839 - val_accuracy: 0.1608\n",
            "Epoch 6/6\n",
            "24778/24778 [==============================] - 2381s 96ms/step - loss: 4.8812 - accuracy: 0.1903 - val_loss: 5.2766 - val_accuracy: 0.1643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9142645510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPt9k9k0Tphf"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFGArmCzWzeh"
      },
      "source": [
        "def LSTMgenerate(seeding, prefix):\r\n",
        "  seed = seeding\r\n",
        "  sentence = prefix\r\n",
        "  for i in range(20):\r\n",
        "    x_pred = np.zeros((len(seeding), len(words)))\r\n",
        "    for t, word in enumerate(seed):\r\n",
        "      x_pred[t, word_indices[word]] = 1.\r\n",
        "    preds = Lmodel.predict(x_pred, verbose=0)[0]\r\n",
        "    next_index = sample(preds,10)\r\n",
        "    next_word = indices_word[next_index]\r\n",
        "    sentence.append(next_word)\r\n",
        "    seed = seed[1:]\r\n",
        "    seed.append(next_word)\r\n",
        "    if \"\\n\" in next_word:\r\n",
        "      break\r\n",
        "  return sentence"
      ],
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH8wnn_w_1ZU"
      },
      "source": [
        "# Rhyming Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05TbQNLQhfbr"
      },
      "source": [
        "STRESSES = {'AA1', 'AE1', 'AH1', 'AO1', 'AW1', 'AY1', 'EH1', 'ER1', 'EY1', 'IH1', 'IY1', 'OW1', 'OY1', 'UH1', 'UW1'}\r\n",
        "\r\n",
        "\r\n",
        "file = open(\"dict.txt\", \"r\")\r\n",
        "\r\n",
        "contents = file.read()\r\n",
        "PHODICT = ast.literal_eval(contents)\r\n",
        "\r\n",
        "file.close()\r\n",
        "\r\n",
        "def isSubList(listA, listB):\r\n",
        "    if len(listA) < len(listB):\r\n",
        "        return isSubList(listB, listA)\r\n",
        "    n = len(listB)\r\n",
        "    for start in range(len(listA)-n+1):\r\n",
        "        if all(listA[start+i] == listB[i] for i in range(n)):\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def getRhymes(word):\r\n",
        "    sounds = PHODICT[word]\r\n",
        "    for index,sound in enumerate(reversed(sounds)):\r\n",
        "        if sound in STRESSES:\r\n",
        "            ending = sounds[-index-1:]\r\n",
        "            break\r\n",
        "    yielded = set()\r\n",
        "    for wordB, soundsB in PHODICT.items():\r\n",
        "        if (ending == soundsB[-index-1:]) and (soundsB not in yielded) and (not isSubList(sounds, soundsB)):\r\n",
        "            yielded.add(soundsB)\r\n",
        "            yield wordB\r\n",
        "\r\n"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGmw9NiEP-5t"
      },
      "source": [
        "#Generation Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kifyJ4H6m3KM"
      },
      "source": [
        "def rhymeFinder(inWord):\r\n",
        "  lastWord = inWord\r\n",
        "  sameRhyme = []\r\n",
        "  for word in getRhymes(lastWord.upper()):\r\n",
        "    sameRhyme.append(word.lower())\r\n",
        "  outWord = random.choice(sameRhyme)\r\n",
        "  return outWord\r\n",
        "\r\n",
        "def reverseSentence(inList):\r\n",
        "  words = inList[0].split()\r\n",
        "  outStr = ' '.join(reversed(words))\r\n",
        "  return outStr\r\n",
        "\r\n",
        "def reverseW(line):\r\n",
        "  words = line.split()\r\n",
        "  reversed_words = ' '.join(reversed(words))\r\n",
        "  return reversed_words\r\n",
        "\r\n",
        "def remove_values_from_list(the_list, val):\r\n",
        "   return [value.lower() for value in the_list if value != val]"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYC2VmEKJr0W",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7f38ab-c1c9-4995-e073-9a5e3bfade5c"
      },
      "source": [
        "firstSeed = \"You and me forever \"\n",
        "allLyrics = []\n",
        "\n",
        "BART_sentence = generate_lyrics(seed_line = firstSeed, num_lines = 2, model_ = model, startW = None,\n",
        "                           noise_percent = 0.5, multiple_lines = False, max_line_history = 1)\n",
        "allLyrics.append(BART_sentence[-1])\n",
        "\n",
        "startword = rhymeFinder(BART_sentence[-1].split()[-1])\n",
        "\n",
        "seed =  BART_sentence[-1].split(\" \")\n",
        "seed = remove_values_from_list(seed, \"\")\n",
        "seed.reverse()\n",
        "prefix =  [startword]\n",
        "\n",
        "LSoutput = LSTMgenerate(seed, prefix)\n",
        "LSoutput = ' '.join(LSoutput)\n",
        "LS_sentence = reverseW(LSoutput)\n",
        "LS_sentence[0].capitalize()\n",
        "\n",
        "allLyrics.append(LS_sentence)\n",
        "print(allLyrics)"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You and me forever\n",
            "You and me forever\n",
            "[' You and me forever', 'hell whatsoever']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwvQWG7FWa_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847ffa95-ddc3-4bd8-c112-f97e5c73cdfd"
      },
      "source": [
        "!pip install rake-nltk\r\n",
        "from rake_nltk import Rake\r\n",
        "\r\n",
        "r = Rake()\r\n",
        "r.extract_keywords_from_sentences(allLyrics)\r\n",
        "keywords = r.get_ranked_phrases()\r\n",
        "\r\n",
        "keySentence = ''\r\n",
        "for i in keywords:\r\n",
        "  keySentence += i\r\n",
        "  keySentence += ' '"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rake-nltk in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rake-nltk) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->rake-nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJrpmRi7lxjR",
        "outputId": "cc9e0b67-a818-42cb-cd2d-dd2c32c3130e"
      },
      "source": [
        "BART_sentence1 = generate_lyrics(seed_line = keySentence, num_lines = 2, model_ = model, startW = None,\r\n",
        "                           noise_percent = 0.25, multiple_lines = False, max_line_history = 1)\r\n",
        "allLyrics.append(BART_sentence1[-1])\r\n",
        "\r\n",
        "startword = rhymeFinder(BART_sentence1[-1].split()[-1])\r\n",
        "\r\n",
        "seed =  BART_sentence1[-1].split(\" \")\r\n",
        "seed = remove_values_from_list(seed, \"\")\r\n",
        "seed.reverse()\r\n",
        "prefix =  [startword]\r\n",
        "\r\n",
        "LSoutput = LSTMgenerate(seed, prefix)\r\n",
        "LSoutput = ' '.join(LSoutput)\r\n",
        "LS_sentence = reverseW(LSoutput)\r\n",
        "LS_sentence[0].capitalize()\r\n",
        "\r\n",
        "allLyrics.append(LS_sentence)\r\n",
        "print(allLyrics)"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "slaughterhouse guap lever forever\n",
            "I'm on a mission to get the fuck out of here\n",
            "[' You and me forever', 'hell whatsoever', \" I'm on a mission to get the fuck out of here\", \"ass guessed western rip sour helicopter feeling again? ends loop badge riches spittin' ourselves do? thirty fall pajamas dancer swimming tier\"]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}